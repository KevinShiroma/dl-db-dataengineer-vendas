# Projeto de Ingestão de Dados com Databricks

Este projeto foi desenvolvido para consolidar meus conhecimentos sobre Big Data e suas ferramentas, utilizando o Databricks como plataforma principal. O objetivo é criar um processo de ingestão de dados de ponta a ponta, culminando na visualização dos dados no Power BI.

## Objetivos do Projeto

- Demonstrar a ingestão de dados utilizando o Databricks.
- Implementar uma arquitetura de dados eficiente e escalável.
- Visualizar os dados processados no Power BI.

## Aprendizados

Durante o desenvolvimento deste projeto, aprendi conceitos importantes, incluindo:

- **Delta Lakehouse**: A importância do Delta Lake na construção de um Lakehouse eficiente.
- **Apache Spark e PySpark**: Compreensão do funcionamento do Apache Spark e como utilizar PySpark para processamento de dados.
- **Arquitetura Medallion**: Desenvolvimento e implementação da arquitetura medallion para organização dos dados.
- **Estratégias de Carga de Dados**: Diferenciação entre cargas de dados FULL e Incremental, e quando utilizar cada uma.
- **Boas Práticas com Delta Lake**: Aplicação de boas práticas ao trabalhar com Delta Lake para garantir a integridade e eficiência dos dados.

## Tecnologias Utilizadas

- Databricks
- Apache Spark
- PySpark
- Delta Lake
- Power BI

## Como Executar o Projeto

1. Clone este repositório:
   ```bash
   git clone https://github.com/seu_usuario/seu_repositorio.git
